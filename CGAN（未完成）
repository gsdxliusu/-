
# coding: utf-8

# In[238]:

import tensorflow as tf
print("TF version:",tf.__version__)
print("GPU is","available" if tf.test.is_gpu_available() else "NOT AVAILABLE")


# In[239]:

import matplotlib.pyplot as plt
import numpy as np
import os
import PIL
from tensorflow.keras import layers
import time
import glob
 
from IPython import display


# In[240]:

fashion_mnist = tf.keras.datasets.fashion_mnist
(train_images,train_labels),(test_images,test_labels) = fashion_mnist.load_data()


print(train_images.shape)


# In[241]:

train_images = train_images.reshape(train_images.shape[0],28,28,1).astype('float32')
train_images = (train_images - 127.5)/127.5

print(train_images.shape)
#将标签进行独热编码
train_labels = tf.one_hot(train_labels,depth = 10)
train_labels = tf.cast(train_labels,tf.float32)


# In[242]:

buffer_size = 60000
batch_size = 256


# In[243]:

train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(buffer_size).batch(batch_size)


# In[244]:

def make_generator_model():
    model = tf.keras.Sequential()
    model.add(layers.Dense(7*7*256,use_bias = False,input_shape = (110,)))
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())
    
    
    model.add(layers.Reshape((7,7,256)))
    assert model.output_shape == (None,7,7,256)
    
    model.add(layers.Conv2DTranspose(128,(5,5),strides = (1,1),padding = 'same',use_bias = False))
    assert model.output_shape == (None,7,7,128)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())
    

    model.add(layers.Conv2DTranspose(64,(5,5),strides = (2,2),padding = 'same',use_bias = False))
    assert model.output_shape == (None,14,14,64)
    model.add(layers.BatchNormalization())
    model.add(layers.LeakyReLU())
    
    model.add(layers.Conv2DTranspose(1,(5,5),strides = (2,2),padding = 'same',use_bias = False,activation = 'tanh'))
    assert model.output_shape == (None,28,28,1)
    
    return model


# In[245]:

generator = make_generator_model()
generator.summary()


# In[ ]:




# In[246]:

def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(layers.Conv2D(64,(5,5),strides = (2,2),padding = 'same',input_shape = [28,28,11]))
    
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))
    
    model.add(layers.Conv2D(128,(5,5),strides = (2,2),padding = 'same'))
    model.add(layers.LeakyReLU())
    model.add(layers.Dropout(0.3))
    
    model.add(layers.Flatten())
    model.add(layers.Dense(1))
   
    return model


# In[247]:

discriminator = make_discriminator_model()
discriminator.summary()



# In[ ]:




# In[248]:

cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits = True)


# In[249]:

def discriminator_loss(real_output,fake_output):
    real_loss = cross_entropy(tf.ones_like(real_output),real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output),fake_output)
    total_loss = real_loss+fake_loss
    return total_loss


# In[250]:

def generator_loss(fake_output):
    return cross_entropy(tf.ones_like(fake_output),fake_output)


# In[251]:

generator_optimizer = tf.keras.optimizers.Adam(1e-4)
discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)


# In[252]:

checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir,"ckpt")
checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer,discriminator_optimizer = discriminator_optimizer,generator = generator,discriminator = discriminator)


# In[253]:

epochs = 100
noise_dim = 100
num_examples_to_generate = 100


# In[254]:

seed = tf.random.normal([num_examples_to_generate,noise_dim])
print(seed.shape)
labels = [i%10 for i in range(num_examples_to_generate)]

labels = tf.one_hot(labels,depth = 10)
print(labels.shape)
labels = tf.cast(labels,tf.float32)
print(labels.shape)
seed = tf.concat([seed,labels],1)
print(seed.shape)


# In[264]:

@tf.function
def train_step(data_batch):
    
    
    images = data_batch[0]
    labels = data_batch[1]
    print(labels.shape)
    print(images.shape)
    with tf.GradientTape() as gen_tape,tf.GradientTape() as disc_tape:
        noise = tf.random.normal([images.get_shape()[0], noise_dim,1])
        print(images.get_shape()[0])

        print(noise.shape)
        noise_input = tf.concat([noise,labels],1)        
        generated_images = generator(noise_input,training = True)
        
        labels_input = tf.reshape(labels,[images.get_shape()[0],1,1,10])
        
        images_input = tf.concat([images,labels_input*tf.ones([images.get_shape()[0],28,28,10])],3)
        
        generated_input = tf.concat([generated_images,labels_input*tf.ones([images.get_shape()[0],28,28,10])],3)
        
        real_output = discriminator(images_input,training = True)
        fake_output = discriminator(generated_input,training = True)
        
        gen_loss = generator_loss(fake_output)
        disc_loss = discriminator_loss(real_output,fake_output)
        
    gradients_of_generator = gen_tape.gradient(gen_loss,generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss,discriminator.trainable_variables)
    
    generator_optimizer.apply_gradients(zip(gradients_of_generator,generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator,discriminator.trainable_variables))






# In[ ]:




# In[ ]:




# In[ ]:




# In[265]:

def train(dataset,epochs):
    for epoch in range(epochs):
        start = time.time()
        
        for data_batch in dataset:
            train_step(data_batch)
        
        display.clear_output(wait = True)
        generate_and_save_images(generator,epoch+1,seed)
        
        if(epoch+1) % 5 ==  0:
            checkpoint.save(file_prefix = checkpoint_prefix)
            
        print('Time for epoch {} is {} sec'.format(epoch+1,time.time()-start))


# In[266]:

def generate_and_save_images(model,epoch,test_input):
    predictions = model(test_input,training = False)
    
    fig = plt.figure(figsize = (10,10))
    
    for i in range(predictions.shape[0]):
        plt.subplot(10,10,i+1)
        plt.imshow(predictions[i,:,:,0]*127.5+127.5,cmap = 'gray')
        plt.axis('off')
        
    plt.savefig('Cimage_at_epoch_{:04d}.png'.format(epoch))
    plt.show()
   


# In[ ]:




# In[267]:


get_ipython().run_cell_magic('time', '', 'train(train_dataset,epochs)')


# In[ ]:




# In[ ]:




# In[ ]:



